{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09545f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1626a9a153c64c2ab8063826c3b0f190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='longrope': {'long_mscale', 'short_mscale'}\n",
      "This model has set a `original_max_position_embeddings` field, to be used together with `max_position_embeddings` to determine a scaling factor. Please set the `factor` field of `rope_scaling`with this ratio instead -- we recommend the use of this field over `original_max_position_embeddings`, as it is compatible with most model architectures.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhimoeConfig {\n",
      "  \"architectures\": [\n",
      "    \"PhiMoEForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_phimoe.PhiMoEConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_phimoe.PhiMoEForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"input_jitter_noise\": 0.01,\n",
      "  \"intermediate_size\": 6400,\n",
      "  \"lm_head_bias\": true,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"model_type\": \"phimoe\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_experts_per_tok\": 2,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"num_local_experts\": 16,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"output_router_logits\": false,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"long_factor\": [\n",
      "      1.0199999809265137,\n",
      "      1.0299999713897705,\n",
      "      1.0399999618530273,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.059999942779541,\n",
      "      1.059999942779541,\n",
      "      1.059999942779541,\n",
      "      1.059999942779541,\n",
      "      1.059999942779541,\n",
      "      1.059999942779541,\n",
      "      1.0999999046325684,\n",
      "      1.1799999475479126,\n",
      "      1.1799999475479126,\n",
      "      1.3700000047683716,\n",
      "      1.4899998903274536,\n",
      "      2.109999895095825,\n",
      "      2.8899998664855957,\n",
      "      3.9499998092651367,\n",
      "      4.299999713897705,\n",
      "      6.429999828338623,\n",
      "      8.09000015258789,\n",
      "      10.690000534057617,\n",
      "      12.050000190734863,\n",
      "      18.229999542236328,\n",
      "      18.84000015258789,\n",
      "      19.899999618530273,\n",
      "      21.420000076293945,\n",
      "      26.200000762939453,\n",
      "      34.28000259399414,\n",
      "      34.590003967285156,\n",
      "      38.730003356933594,\n",
      "      40.22000503540039,\n",
      "      42.54000473022461,\n",
      "      44.000003814697266,\n",
      "      47.590003967285156,\n",
      "      54.750003814697266,\n",
      "      56.19000244140625,\n",
      "      57.44000244140625,\n",
      "      57.4900016784668,\n",
      "      61.20000076293945,\n",
      "      61.540000915527344,\n",
      "      61.75,\n",
      "      61.779998779296875,\n",
      "      62.06999969482422,\n",
      "      63.11000061035156,\n",
      "      63.43000030517578,\n",
      "      63.560001373291016,\n",
      "      63.71000289916992,\n",
      "      63.92000198364258,\n",
      "      63.94000244140625,\n",
      "      63.94000244140625,\n",
      "      63.96000289916992,\n",
      "      63.980003356933594,\n",
      "      64.0300064086914,\n",
      "      64.0300064086914,\n",
      "      64.0300064086914,\n",
      "      64.04000854492188,\n",
      "      64.10000610351562,\n",
      "      64.19000244140625,\n",
      "      64.20999908447266,\n",
      "      64.75,\n",
      "      64.95999908447266\n",
      "    ],\n",
      "    \"long_mscale\": 1.243163121016122,\n",
      "    \"original_max_position_embeddings\": 4096,\n",
      "    \"rope_type\": \"longrope\",\n",
      "    \"short_factor\": [\n",
      "      1.0,\n",
      "      1.0399999618530273,\n",
      "      1.0399999618530273,\n",
      "      1.0399999618530273,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.059999942779541,\n",
      "      1.059999942779541,\n",
      "      1.0699999332427979,\n",
      "      1.0699999332427979,\n",
      "      1.0699999332427979,\n",
      "      1.0699999332427979,\n",
      "      1.1399999856948853,\n",
      "      1.159999966621399,\n",
      "      1.159999966621399,\n",
      "      1.159999966621399,\n",
      "      1.159999966621399,\n",
      "      1.1799999475479126,\n",
      "      1.1999999284744263,\n",
      "      1.3199999332427979,\n",
      "      1.3399999141693115,\n",
      "      1.3499999046325684,\n",
      "      1.3999998569488525,\n",
      "      1.4799998998641968,\n",
      "      1.4999998807907104,\n",
      "      1.589999794960022,\n",
      "      1.6499998569488525,\n",
      "      1.71999990940094,\n",
      "      1.8999998569488525,\n",
      "      1.9099998474121094,\n",
      "      1.9099998474121094,\n",
      "      1.9899998903274536,\n",
      "      1.9999998807907104,\n",
      "      1.9999998807907104,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.009999990463257,\n",
      "      2.0999999046325684,\n",
      "      2.319999933242798,\n",
      "      2.419999837875366,\n",
      "      2.5899999141693115,\n",
      "      2.7899999618530273\n",
      "    ],\n",
      "    \"short_mscale\": 1.243163121016122,\n",
      "    \"type\": \"longrope\"\n",
      "  },\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"router_aux_loss_coef\": 0.0,\n",
      "  \"router_jitter_noise\": 0.01,\n",
      "  \"sliding_window\": 131072,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.55.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"microsoft/Phi-3.5-MoE-instruct\")\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f5df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alignment_benchmark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

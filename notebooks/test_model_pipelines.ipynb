{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ceedc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b692472",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, pipeline\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m BASE_DIR = os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))  \n\u001b[32m      7\u001b[39m PROJECT_ROOT = os.path.abspath(os.path.join(BASE_DIR, \u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      8\u001b[39m CONFIG_DIR = os.path.join(PROJECT_ROOT, \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "\n",
    "\n",
    "model_id=\"state-spaces/mamba-2.8b-slimpj\"\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\"text-generation\", \n",
    "                model=model_id,\n",
    "                device=\"cuda\", \n",
    "                torch_dtype=torch.bfloat16\n",
    "                #tokenizer=tokenizer,\n",
    "                #cache_dir=\"/mnt/dv/wid/projects3/Rogers-muri-human-ai/zstuddiford\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbb930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae_concepts_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
